{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a24ecb2-e8a8-494c-b949-842a8a399832",
   "metadata": {},
   "source": [
    "# Import all the necessary libraries\n",
    "pandas - to load and handle data\n",
    "TfidfVectorizer - to turn text into numbers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4a58fe7-2bd4-4661-9dfe-8282b6c3a2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89d9d26b-1178-4e15-b5ff-a4e08f18a9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   polarity                                               text\n",
      "0         0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
      "1         0  is upset that he can't update his Facebook by ...\n",
      "2         0  @Kenichan I dived many times for the ball. Man...\n",
      "3         0    my whole body feels itchy and like its on fire \n",
      "4         0  @nationwideclass no, it's not behaving at all....\n"
     ]
    }
   ],
   "source": [
    "# data load\n",
    "df = pd.read_csv(r'C:\\Users\\Pradip Chaurel\\OneDrive\\Desktop\\MLprojects\\Twitter Sentiment Analysis\\twitter_data.csv',encoding='latin-1',header=None)\n",
    "df = df[[0,5]]  # keeping only two columns\n",
    "df.columns = ['polarity','text']\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dbd3ddc7-13d5-4f08-923d-13c40764cb32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    800000\n",
      "1    800000\n",
      "Name: polarity, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# keep only positive and negative sentiments\n",
    "# removing neutral tweets where polarity is 2\n",
    "# polarity 0 means negative and 4 becomes 1 for positive.\n",
    "\n",
    "df = df[df.polarity != 2]\n",
    "df['polarity'] = df['polarity'].map({0:0,4:1})\n",
    "print(df['polarity'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "07be5f06-7a20-4f7a-8ad2-a3ac50242fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
      "1  is upset that he can't update his Facebook by ...   \n",
      "2  @Kenichan I dived many times for the ball. Man...   \n",
      "3    my whole body feels itchy and like its on fire    \n",
      "4  @nationwideclass no, it's not behaving at all....   \n",
      "\n",
      "                                          clean_text  \n",
      "0  @switchfoot http://twitpic.com/2y1zl - awww, t...  \n",
      "1  is upset that he can't update his facebook by ...  \n",
      "2  @kenichan i dived many times for the ball. man...  \n",
      "3    my whole body feels itchy and like its on fire   \n",
      "4  @nationwideclass no, it's not behaving at all....  \n"
     ]
    }
   ],
   "source": [
    "# clean the tweets\n",
    "# firstly, convert all text into lowercase for consistency\n",
    "\n",
    "def clean_text(text):\n",
    "    return text.lower()\n",
    "    \n",
    "df['clean_text'] = df['text'].apply(clean_text)\n",
    "print(df[['text','clean_text']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e5c303-f4d2-4e60-94b1-1d7972e44ccb",
   "metadata": {},
   "source": [
    "# split the dataset into training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "062c3010-8e68-48da-8232-b1c67445c4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 1280000\n",
      "Test size: 320000\n"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(\n",
    "    df['clean_text'],\n",
    "    df['polarity'],\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train size:\", len(x_train))\n",
    "print(\"Test size:\", len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aac63d59-ded6-46a8-9178-e180e7d40c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF shape (train): (1280000, 5000)\n",
      "TF-IDF shape (test): (320000, 5000)\n"
     ]
    }
   ],
   "source": [
    "# perform vectorization\n",
    "'''This code creates a TF IDF vectorizer that converts text into\n",
    "numerical features using unigrams and bigrams limited to 5000 features'''\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=5000,ngram_range=(1,2))\n",
    "\n",
    "x_train_tfidf = vectorizer.fit_transform(x_train)\n",
    "x_test_tfidf = vectorizer.fit_transform(x_test)\n",
    "\n",
    "print(\"TF-IDF shape (train):\", x_train_tfidf.shape)\n",
    "print(\"TF-IDF shape (test):\", x_test_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54c794a-cc48-4f44-8654-601153abc85d",
   "metadata": {},
   "source": [
    "# Train Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "032f8e11-6668-45ac-8207-e841ec555f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Naive Bayes Accuracy: 0.616253125\n",
      "\n",
      "BernoulliNB Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.54      0.58    159494\n",
      "           1       0.60      0.69      0.64    160506\n",
      "\n",
      "    accuracy                           0.62    320000\n",
      "   macro avg       0.62      0.62      0.61    320000\n",
      "weighted avg       0.62      0.62      0.61    320000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bnb = BernoulliNB()\n",
    "bnb.fit(x_train_tfidf,y_train)\n",
    "bnb_pred = bnb.predict(x_test_tfidf)\n",
    "\n",
    "print(\"Bernoulli Naive Bayes Accuracy:\", accuracy_score(y_test,bnb_pred))\n",
    "\n",
    "print(\"\\nBernoulliNB Classification Report:\\n\", classification_report(y_test,bnb_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546263c9-2942-4225-a06a-6f588f197233",
   "metadata": {},
   "source": [
    "# Train SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cd2f3829-e3e6-4805-90de-7a49686aece7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.576825\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.61      0.59    159494\n",
      "           1       0.58      0.55      0.56    160506\n",
      "\n",
      "    accuracy                           0.58    320000\n",
      "   macro avg       0.58      0.58      0.58    320000\n",
      "weighted avg       0.58      0.58      0.58    320000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm = LinearSVC(max_iter=1000)\n",
    "svm.fit(x_train_tfidf,y_train)\n",
    "\n",
    "svm_pred = svm.predict(x_test_tfidf)\n",
    "\n",
    "print(\"SVM Accuracy:\", accuracy_score(y_test,svm_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test,svm_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17faa302-c008-4e12-bceb-bddc3a39d816",
   "metadata": {},
   "source": [
    "# Train logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b8c85a52-ae03-41fb-8f2a-f7dbba118317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.5811375\n",
      "\n",
      "Logistic Regression Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.60      0.59    159494\n",
      "           1       0.59      0.56      0.57    160506\n",
      "\n",
      "    accuracy                           0.58    320000\n",
      "   macro avg       0.58      0.58      0.58    320000\n",
      "weighted avg       0.58      0.58      0.58    320000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(max_iter=1000)\n",
    "logreg.fit(x_train_tfidf,y_train)\n",
    "\n",
    "logreg_pred = logreg.predict(x_test_tfidf)\n",
    "\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test,logreg_pred))\n",
    "\n",
    "print(\"\\nLogistic Regression Classification Report:\\n\", classification_report(y_test,logreg_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67eefdc-23bd-47cd-8b3e-0f5ec9558ca0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f2c81200-a757-4245-b647-9ae62c728928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Predictions:\n",
      "BernoulliNB: [1 0 1]\n",
      "SVM: [1 0 1]\n",
      "Logistic Regression: [1 0 1]\n"
     ]
    }
   ],
   "source": [
    "# try for sample tweets\n",
    "sample_tweets = [\"I love this!\",\"I hate that!\",\"It was okay, not great.\"]\n",
    "sample_vec = vectorizer.transform(sample_tweets)\n",
    "\n",
    "print(\"\\nSample Predictions:\")\n",
    "print(\"BernoulliNB:\", bnb.predict(sample_vec))\n",
    "print(\"SVM:\", svm.predict(sample_vec))\n",
    "print(\"Logistic Regression:\", logreg.predict(sample_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd28612-7a42-440c-a447-4030cba630c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53890aca-04be-4f96-a017-5d8c59872e34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe16e25-850e-4afb-9ef5-381ba3e5a68d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8011b52b-cc19-44d0-a4b3-c5b53f5555b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c074e1bb-ce9f-4529-a4b1-96d68344387b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
